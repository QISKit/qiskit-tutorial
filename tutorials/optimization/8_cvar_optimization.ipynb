{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Variational Quantum Optimization using CVaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook shows how to use the Conditional Value at Risk (CVaR) objective function introduced in [1] within the variational quantum optimization algorithms provided by Qiskit, particularly `VQE` used within the `MinimumEigenOptimizer`. For a given set of shots and corresponding objective values, the CVaR with confidence level $\\alpha \\in [0, 1]$ is defined as the average of the $\\alpha$ best shots.\n",
    "Thus, $\\alpha = 1$ corresponds to the standard expected value, while $\\alpha=0$ corresponds to the minimum of the given shots.\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "[1] [P. Barkoutsos et al., *Improving Variational Quantum Optimization using CVaR,* Quantum 4, 256 (2020).](https://quantum-journal.org/papers/q-2020-04-20-256/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "from qiskit.aqua.algorithms import NumPyMinimumEigensolver, VQE, QAOA\n",
    "# from qiskit.aqua.operators import PauliExpectation, CVaRExpectation\n",
    "from qiskit.optimization import QuadraticProgram\n",
    "from qiskit.optimization.converters import LinearEqualityToPenalty\n",
    "from qiskit.optimization.algorithms import MinimumEigenOptimizer, CplexOptimizer\n",
    "from qiskit import execute, Aer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from docplex.mp.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Optimization\n",
    "In the following we define a problem instance for portfolio optimization as introduced in [1].<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare problem instance\n",
    "n = 6            # number of assets\n",
    "q = 0.5          # risk factor\n",
    "budget = n // 2  # budget\n",
    "penalty = 2*n    # scaling of penalty term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance from [1]\n",
    "mu = np.array([0.7313, 0.9893, 0.2725, 0.8750, 0.7667, 0.3622])\n",
    "sigma = np.array([\n",
    "    [ 0.7312, -0.6233,  0.4689, -0.5452, -0.0082, -0.3809],\n",
    "    [-0.6233,  2.4732, -0.7538,  2.4659, -0.0733,  0.8945],\n",
    "    [ 0.4689, -0.7538,  1.1543, -1.4095,  0.0007, -0.4301],\n",
    "    [-0.5452,  2.4659, -1.4095,  3.5067,  0.2012,  1.0922],\n",
    "    [-0.0082, -0.0733,  0.0007,  0.2012,  0.6231,  0.1509],\n",
    "    [-0.3809,  0.8945, -0.4301,  1.0922,  0.1509,  0.8992]\n",
    "])\n",
    "\n",
    "# or create random instance\n",
    "# mu, sigma = portfolio.random_model(n, seed=123)  # expected returns and covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create docplex model\n",
    "mdl = Model('portfolio_optimization')\n",
    "x = mdl.binary_var_list('x{}'.format(i) for i in range(n))\n",
    "objective = mdl.sum([mu[i]*x[i] for i in range(n)])\n",
    "objective -= q * mdl.sum([sigma[i,j]*x[i]*x[j] for i in range(n) for j in range(n)])\n",
    "mdl.maximize(objective)\n",
    "mdl.add_constraint(mdl.sum(x[i] for i in range(n)) == budget)\n",
    "\n",
    "# case to \n",
    "qp = QuadraticProgram()\n",
    "qp.from_docplex(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimal function value: 1.27835\n",
       "optimal value: [1. 1. 0. 0. 1. 0.]\n",
       "status: SUCCESS"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solve with CPLEX as reference\n",
    "opt_result = CplexOptimizer().solve(qp)\n",
    "opt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we convert the problem to an unconstrained problem for further analysis,\n",
    "# otherwise this would not be necessary as the MinimumEigenSolver would do this \n",
    "# translation automatically\n",
    "linear2penalty = LinearEqualityToPenalty(penalty=penalty)\n",
    "qp = linear2penalty.convert(qp)\n",
    "_, offset = qp.to_ising()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Eigen Optimizer using VQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set classical optimizer\n",
    "maxiter = 100\n",
    "optimizer = COBYLA(maxiter=maxiter)\n",
    "\n",
    "# set variational ansatz\n",
    "var_form = RealAmplitudes(n, reps=1)\n",
    "m = var_form.num_parameters\n",
    "\n",
    "# set backend\n",
    "backend_name = 'qasm_simulator'  # use this for QASM simulator\n",
    "# backend_name = 'statevector_simulator'  # use this for statevector simlator\n",
    "backend = Aer.get_backend(backend_name)  \n",
    "\n",
    "# run variational optimization for different values of alpha\n",
    "alphas = [1.0, 0.50, 0.25]  # confidence levels to be evaluated\n",
    "initial_point = np.random.rand(m)  # same random initial set of parameters for all experiments\n",
    "pauli_exp = PauliExpectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries to store optimization progress and results\n",
    "objectives = {alpha: [] for alpha in alphas}  # set of tested objective functions w.r.t. alpha\n",
    "results = {}  # results of minimum eigensolver w.r.t alpha\n",
    "\n",
    "# callback to store intermediate results\n",
    "def callback(i, params, obj, stddev, alpha):\n",
    "    objectives[alpha] += [-(obj + offset)]  # we translate the objective to the original problem\n",
    "\n",
    "# loop over all given alpha values\n",
    "for alpha in alphas:\n",
    "    \n",
    "    # initialize CVaR_alpha objective\n",
    "    cvar_exp = CVaRExpectation(alpha, pauli_exp)\n",
    "    \n",
    "    # initialize VQE\n",
    "    vqe = VQE(expectation=cvar_exp, optimizer=optimizer, var_form=var_form, quantum_instance=backend,\n",
    "             callback=lambda i, params, obj, stddev: callback(i, params, obj, stddev, alpha))\n",
    "   \n",
    "    # initialize optimization algorithm based on CVaR-VQE\n",
    "    opt_alg = MinimumEigenOptimizer(vqe)\n",
    "\n",
    "    # solve problem\n",
    "    results[alpha] = opt_alg.solve(qp)\n",
    "    print('alpha = {}:'.format(alpha))\n",
    "    print(results[alpha])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot resulting history of objective values - note that this \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([0, maxiter], [opt_result.fval, opt_result.fval], 'r--', linewidth=2, label='optimum')\n",
    "for alpha in alphas:\n",
    "    plt.plot(objectives[alpha], label='alpha = %.2f' % alpha, linewidth=2)\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.xlim(0, maxiter)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('iterations', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('objective value', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and sort all objective values\n",
    "objective_values = np.zeros(2**n)\n",
    "for i in range(2**n):\n",
    "    x_bin = ('{0:0%sb}' % n).format(i)\n",
    "    x = [0 if x_ == '0' else 1 for x_ in reversed(x_bin)]\n",
    "    objective_values[i] = qp.objective.evaluate(x)\n",
    "ind = np.argsort(objective_values)\n",
    "\n",
    "# evaluate final optimal probability for each alpha\n",
    "probabilities = np.zeros(len(objective_values))\n",
    "for alpha in alphas:\n",
    "    if backend_name == 'qasm_simulator':\n",
    "        counts = results[alpha].min_eigen_solver_result.eigenstate\n",
    "        shots = sum(counts.values())\n",
    "        for key, val in counts.items():\n",
    "            i = int(key, 2)\n",
    "            probabilities[i] = val / shots\n",
    "    else:\n",
    "        probabilities = np.abs(results[alpha].min_eigen_solver_result.eigenstate)**2\n",
    "    print('optimal probabilitiy (alpha = %.2f):  %.4f' % (alpha, probabilities[ind][-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit.tools.jupyter\n",
    "%qiskit_version_table\n",
    "%qiskit_copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('qiskit-dev': conda)",
   "language": "python",
   "name": "python37664bitqiskitdevcondafac8dc924b07415588658d1bdd42639b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
